{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06d6c1-01f9-4193-bd2f-49766ff2ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21fc2c-df04-4701-90b3-bf808402051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "MAX_LEN = 120\n",
    "TRAIN_FRACTION = 0.9\n",
    "EMBEDDING_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ea6c5-7d8f-4799-8931-79fbbf0e87dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72fd8108-7d54-4b6f-aa84-9bcd7287b7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1561841, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv(\"../../datasets/language-dataset/hi-en-text/hindi_english_parallel.csv\")\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6e3580-566f-4e72-b024-32de5c0776e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hindi', 'english'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8142115-723d-4d97-896e-25652bd8c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['wc'] = ds['english'].map(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80bbde6a-70f8-4692-b3eb-f7f525e43a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "      <th>wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "      <td>Accerciser Accessibility Explorer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
       "      <td>A list of plugins that are disabled by default</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
       "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
       "\n",
       "                                          english  wc  \n",
       "0  Give your application an accessibility workout   6  \n",
       "1               Accerciser Accessibility Explorer   3  \n",
       "2  The default plugin layout for the bottom panel   8  \n",
       "3     The default plugin layout for the top panel   8  \n",
       "4  A list of plugins that are disabled by default   9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "365e7c78-32b5-425a-a9c4-633612452f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ae8487d-ab11-4dab-ba19-f47e3ecdbd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([c in string.ascii_letters for c in list(\"abc2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a615f01-8117-47fb-bc0e-5ca5394230fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isalphanum(x):\n",
    "    return all([all([c in string.ascii_letters for c in list(w)]) for w in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85a003a6-e2fd-413d-a97a-0e94285e917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['isalphanum'] = ds['english'].map(lambda x: isalphanum(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f23568ee-d0a3-456f-9b35-8984c4e92c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds[(ds['wc']>10) & (ds['isalphanum'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ea1f290-447c-4256-82fe-aae9da077482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Move a card from the reserve onto the empty ta...\n",
       "1        Move a card or build of cards on to the empty ...\n",
       "2        Undo until there are enough cards to fill all ...\n",
       "3        Move a build of cards on to the empty Tableau ...\n",
       "4        Move a card from the reserve onto the empty ta...\n",
       "                               ...                        \n",
       "10196    We must be determined to defend our independen...\n",
       "10197    What measures are required to be taken to impr...\n",
       "10198    What should be the role of youth in disaster m...\n",
       "10199    With the bulk of our population in the working...\n",
       "10200    You may discover truth but you should apply it...\n",
       "Name: english, Length: 10201, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d6568-4083-4ef2-bbf7-605d313d91da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342704a-cec1-4bfc-9b80-aa130cc5d722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eea6134b-ab14-4a47-9632-b05a58b485da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9037236-3f26-415c-a712-49e6faff11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1945b77-715d-4490-8910-187c06f2e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e312c96-d93f-42c1-9921-017331143117",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Character Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "54a53832-0815-48c2-bd06-03ff3d058585",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharTokenizer:\n",
    "    from tqdm import tqdm\n",
    "    def __init__(self, verbose=0, max_len=1200):\n",
    "        self.verbose = verbose\n",
    "        self.max_len = max_len\n",
    "        self.k2v = None\n",
    "        self.v2k = None\n",
    "        self.mask = None\n",
    "        self.item = None\n",
    "\n",
    "    def fit(self,x):\n",
    "        item = []\n",
    "        mask = []\n",
    "        self.total_items = x.shape[0]\n",
    "        assert type(x) in [pd.core.series.Series, list, np.ndarray], f\"x should be in [pd.Series, list, ndarray] but got, {type(x)}\"\n",
    "        self.unique_chars = CharTokenizer.get_unique(x)\n",
    "        self.k2v = {c:i+1 for i,c in enumerate(self.unique_chars)}\n",
    "        self.v2k = {i+1:c for i,c in enumerate(self.unique_chars)}\n",
    "        for c in self.tqdm(x, total=len(x)):\n",
    "            item.append(self.tokenize(c))\n",
    "            mask.append(self.masked(c))\n",
    "        self.item = np.array(item, dtype=np.int32)\n",
    "        self.mask = np.array(mask, dtype=np.bool)\n",
    "        if self.verbose:\n",
    "            print(f\"total items, {self.item.shape[0]}\")\n",
    "    \n",
    "    def tokenize(self, sen):\n",
    "        tokens = [self.k2v[c] for c in list(sen)]\n",
    "        tokens = tokens[:self.max_len]\n",
    "        padded = [0 for _ in range(self.max_len - len(tokens))]\n",
    "        tokens.extend(padded)\n",
    "        return tokens\n",
    "    \n",
    "    def masked(self, sen):\n",
    "        sen = sen[:self.max_len]\n",
    "        n = len(list(sen))\n",
    "        return [1 for _ in range(n)] + [0 for _ in range(self.max_len - n)]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_unique(dataset):\n",
    "        chars = set()\n",
    "        for s in dataset:\n",
    "            chars.update(set(list(s)))\n",
    "        chars = list(chars)\n",
    "        chars.sort()\n",
    "        return chars\n",
    "    def decode(self, tokens: np.ndarray, mask: np.ndarray=None):\n",
    "        if mask is None:\n",
    "            mask = np.where(tokens != 0 , True, False)\n",
    "        return \"\".join([self.v2k[t] for t in tokens[mask]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "fcb3ee7d-2576-4f61-9478-a0379bfbed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer(max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "8e88106a-c7fc-4781-8d97-254ce9cf7298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10201/10201 [00:00<00:00, 73007.83it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit(dataset['english'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "a4395ed0-091b-42e7-922f-0e3cd08d99ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Move a card from the reserve onto the empty tableau slot'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "dabd4e55-5687-44ca-82b7-823e69523490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.k2v.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c04e6-52ab-4efb-900d-a678b3f3b5d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "550d137a-59dd-4331-ac98-74314c5c437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_data, masks):\n",
    "        self.text_data = text_data\n",
    "        self.masks = masks\n",
    "        \n",
    "    def __getitem__(self, indx):\n",
    "        return torch.tensor(self.text_data[indx]), torch.tensor(self.masks[indx], dtype=torch.bool)\n",
    "    def __len__(self):\n",
    "        return self.text_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a3bd7ca5-0324-418d-b391-12f00e92bb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9180"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(tokenizer.total_items * TRAIN_FRACTION)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6827fe23-bfcd-47f2-b8e8-01a00fc2baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TextDataset(tokenizer.item[:train_size], tokenizer.mask[:train_size])\n",
    "val_ds = TextDataset(tokenizer.item[train_size:], tokenizer.mask[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "564930d6-5991-40a9-8195-d24af8b34ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    pin_memory=True\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30155199-6f86-4a62-b746-993e34540ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56da6631-9927-4a00-ad26-bd629546ffd7",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac313f59-d7da-4a26-85af-b3619d9241e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37f8a87d-8674-49b4-9f50-28144599d32c",
   "metadata": {},
   "source": [
    "### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e98160c6-dd91-4eee-b89e-3df9e5aca3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fdb0f4ca-0c69-4a97-bc7d-ef962c64a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, max_len, emb_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.emb_dim = emb_dim\n",
    "        self.qkv = nn.Linear(emb_dim, 3*emb_dim)\n",
    "        self.register_buffer(\"mask\",torch.tril(torch.ones(max_len, max_len)))\n",
    "    \n",
    "    def forward(self, x, mask=False):\n",
    "        B,T,D = x.shape\n",
    "        q, k, v = self.qkv(x).split(self.emb_dim, dim=2)\n",
    "        qk = (q @ torch.transpose(k,1,2)) * self.emb_dim ** -0.5\n",
    "        if mask:\n",
    "            qk = qk.masked_fill(self.mask!=1,float(\"-inf\"))\n",
    "        att = F.softmax(qk,dim=-1)\n",
    "        return att @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "352f2765-fd5a-423c-880e-ca81320c291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SelfAttention(5,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "f51457f7-183b-4257-aee0-b1cfb28e431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, max_len:int, emb_dim:int, masked:bool):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.emb_dim = emb_dim\n",
    "        self.masked = masked\n",
    "        self.attn = SelfAttention(max_len, emb_dim)\n",
    "    \n",
    "    def forward(self,x:torch.Tensor):\n",
    "        return self.attn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "5e5736ae-5ea1-4b64-918f-d7cadd8cab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextModel(nn.Module):\n",
    "    def __init__(self, token_size, max_len, emb_dim, n_block):\n",
    "        super().__init__()\n",
    "        self.token_size = token_size\n",
    "        self.max_len = max_len\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_block = n_block\n",
    "        self.embedding = nn.Embedding(token_size,emb_dim)\n",
    "        self.positional = nn.Embedding(token_size,emb_dim)\n",
    "        self.blk = nn.ModuleList([Block(max_len, emb_dim, masked=True) for _ in range(n_block)])\n",
    "        self.final_mlp = nn.Linear(emb_dim, token_size)\n",
    "    \n",
    "    def forward(self,x,y=None):\n",
    "        x = self.embedding(x) + self.positional(x)\n",
    "        for blk in self.blk:\n",
    "            x = blk(x)\n",
    "        x = self.final_mlp(x)\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = F.cross_entropy( x.view(-1,x.shape[-1]), y.view(-1) )\n",
    "        return x, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "8c3f6de2-7174-44fa-a468-70453979b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextModel(len(tokenizer.k2v.keys()),MAX_LEN, EMBEDDING_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "fb72d6b4-504d-4ebd-bd32-7d09b7ceaf35",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-506-768a4d358b40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\deepa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32mc:\\users\\deepa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\deepa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    600\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\deepa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    923\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[0;32m    924\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[1;32m--> 925\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\deepa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "fe7a2337-ed35-4d41-a9df-f8f7728b9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.from_numpy(tokenizer.item[0]).view(1,-1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "1faa1147-0d5b-41b9-aada-687fb9515019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "5e166042-b7ae-459d-822b-761a372c726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adagrad(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "fbff61a6-51b5-4dea-b77d-6b36ff77dbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9472, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "logit, loss = model(a,a)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "f90408b7-6f2d-480b-adf9-c73f1d9419f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0510184-f8a4-4b7d-9ff8-b8b7ab246937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "26a6aa75-749c-4d71-aa81-d3cd4a796345",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.argmax(logit,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "7058d313-5d49-423b-a8e5-e48f91d67720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(pred.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87271e15-306d-4e40-bfeb-4b88667232bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6d27e-ab21-4cb7-957e-02e240a2304b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8118efef-b7f0-47eb-b673-333abbe141c2",
   "metadata": {},
   "source": [
    "### Training scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b58420-64ed-41c3-9834-b76ae7cfb84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
